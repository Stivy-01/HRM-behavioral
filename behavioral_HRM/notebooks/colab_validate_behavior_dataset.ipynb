{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HRM Behavior Dataset Validation (Colab)\n",
        "\n",
        "This notebook validates the HRM-formatted behavior dataset (`behavior-v1`) by:\n",
        "- Loading `inputs/labels` arrays and `dataset.json`\n",
        "- Reading `vocab.json`\n",
        "- Printing shapes/metadata and a token preview\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "DATA_ROOT = \"/content/behavior-v1\"  #@param {type:\"string\"}\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Validate dataset structure and preview tokens\n",
        "import os, json\n",
        "import numpy as np\n",
        "\n",
        "assert os.path.isdir(DATA_ROOT), f\"Missing {DATA_ROOT}\"\n",
        "\n",
        "vocab_path = os.path.join(DATA_ROOT, 'vocab.json')\n",
        "vocab = json.load(open(vocab_path, 'r')) if os.path.exists(vocab_path) else []\n",
        "print('vocab_size', len(vocab))\n",
        "\n",
        "for split in ['train','val','test']:\n",
        "  d = os.path.join(DATA_ROOT, split)\n",
        "  p_inputs = os.path.join(d, 'all__inputs.npy')\n",
        "  p_labels = os.path.join(d, 'all__labels.npy')\n",
        "  p_meta   = os.path.join(d, 'dataset.json')\n",
        "\n",
        "  if not os.path.exists(p_inputs):\n",
        "    print(split, '(missing)')\n",
        "    continue\n",
        "\n",
        "  inputs = np.load(p_inputs, mmap_mode='r')\n",
        "  labels = np.load(p_labels, mmap_mode='r')\n",
        "  meta = json.load(open(p_meta,'r'))\n",
        "\n",
        "  print(split, 'inputs', inputs.shape, 'labels', labels.shape, 'seq_len(meta)', meta.get('seq_len'), 'vocab(meta)', meta.get('vocab_size'))\n",
        "\n",
        "  p_pids = os.path.join(d, 'all__puzzle_identifiers.npy')\n",
        "  p_pidx = os.path.join(d, 'all__puzzle_indices.npy')\n",
        "  p_gidx = os.path.join(d, 'all__group_indices.npy')\n",
        "  if os.path.exists(p_pids):\n",
        "    pids = np.load(p_pids)\n",
        "    pidx = np.load(p_pidx)\n",
        "    gidx = np.load(p_gidx)\n",
        "    print(split, 'puzzles', pids.shape, 'puzzle_indices', pidx.shape, 'group_indices', gidx.shape)\n",
        "\n",
        "  if inputs.shape[0] > 0 and len(vocab):\n",
        "    row = inputs[0][:32].tolist()\n",
        "    toks = [vocab[t] if 0 <= t < len(vocab) else f'<unk:{t}>' for t in row]\n",
        "    print(split, 'preview', toks)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
